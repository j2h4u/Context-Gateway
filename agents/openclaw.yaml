# OpenClaw Agent Configuration
# ================================
# OpenClaw personal AI assistant with gateway compression support
#
# Usage:
#   ./start_agent.sh openclaw -c tool_output_compresr_api_0.5.yaml
#   ./start_agent.sh openclaw -c tool_output_passthrough.yaml
#
# OpenClaw needs its own gateway running for the TUI to work.
# This config starts OpenClaw's gateway, then opens the TUI.
# LLM calls are routed through our Context Gateway via providers config.

agent:
  name: "openclaw"
  display_name: "OpenClaw"
  description: "OpenClaw personal AI assistant"

  # Available models for interactive selection
  models:
    - id: "anthropic/claude-opus-4-5"
      name: "Claude Opus 4.5"
      provider: "anthropic"
    - id: "anthropic/claude-sonnet-4-20250514"
      name: "Claude Sonnet 4"
      provider: "anthropic"
    - id: "openai/gpt-5-nano"
      name: "GPT-5 Nano"
      provider: "openai"
    - id: "openai/gpt-5-mini"
      name: "GPT-5 Mini"
      provider: "openai/gpt-5-mini"
    - id: "openai/gpt-5"
      name: "GPT-5"
      provider: "openai/gpt-5"

  # Default model (can be overridden interactively)
  default_model: "anthropic/claude-opus-4-5"

  environment:
    # Both providers routed through Context Gateway
    - name: "ANTHROPIC_API_KEY"
      value: "${ANTHROPIC_API_KEY}"
    - name: "ANTHROPIC_BASE_URL"
      value: "http://localhost:${GATEWAY_PORT}"
    - name: "OPENAI_API_KEY"
      value: "${OPENAI_API_KEY}"
    - name: "OPENAI_BASE_URL"
      value: "http://localhost:${GATEWAY_PORT}"

  command:
    check: "command -v openclaw &> /dev/null"
    run: "openclaw tui --token localdev"
    # pre_run is handled by start_agent.sh which creates the config with selected model
    install: "npm install -g openclaw@latest"
    fallback_message: "OpenClaw not found."
