# =============================================================================
# Context Gateway - External LLM Providers
# =============================================================================
# This file defines the available external LLM providers and their models.
# These are the providers that the gateway can proxy requests to.
# 
# NOTE: This file is used ONLY by the TUI wizard for config creation.
# It is NOT loaded by the gateway proxy itself.
#
# Update this file to add new models without recompiling.
# Last updated: February 2026
# =============================================================================

providers:
  anthropic:
    display_name: "Claude Code CLI"
    env_var: "ANTHROPIC_API_KEY"
    default_model: "claude-haiku-4-5"
    models:
      - "claude-haiku-4-5"  # Fastest, most cost-efficient (recommended)
      - "claude-sonnet-4-5" # Best balance of speed and intelligence
      - "claude-opus-4-5"   # Highly intelligent
      - "claude-opus-4-6"   # Most intelligent, for complex tasks

  gemini:
    display_name: "Google Gemini"
    env_var: "GEMINI_API_KEY"
    default_model: "gemini-3-flash"
    models:
      - "gemini-3-flash"       # Newest balanced model
      - "gemini-3-pro"         # Newest most intelligent
      - "gemini-2.5-flash"     # Best price-performance
      - "gemini-2.5-flash-lite" # Ultra fast, cost-efficient
      - "gemini-2.5-pro"       # Advanced thinking model

  openai:
    display_name: "OpenAI"
    env_var: "OPENAI_API_KEY"
    default_model: "gpt-5-nano"
    models:
      - "gpt-5-nano"           # Fastest, most cost-efficient (recommended)
      - "gpt-5-mini"           # Fast, cost-efficient for well-defined tasks
      - "gpt-5.2"              # Best for coding and agentic tasks
      - "gpt-5.2-pro"          # Smarter, more precise responses
